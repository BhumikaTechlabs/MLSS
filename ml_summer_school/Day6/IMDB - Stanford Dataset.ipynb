{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_folder = \"aclImdb/train/pos/\"\n",
    "train_neg_folder = \"aclImdb/train/neg/\"\n",
    "train_unsup_folder = \"aclImdb/train/unsup/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "train_pos_files = os.listdir(train_pos_folder)\n",
    "print len(train_pos_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "train_unsup_files = os.listdir(train_unsup_folder)\n",
    "print len(train_unsup_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "train_neg_files = os.listdir(train_neg_folder)\n",
    "print len(train_neg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_df = pd.DataFrame(columns=[\"Unique ID\",\"File Name\",\"File ID\",\"Rating\",\"Review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.8 s, sys: 156 ms, total: 46 s\n",
      "Wall time: 46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = \"train_pos_\"\n",
    "for f in train_pos_files:\n",
    "    open_f = open(train_pos_folder+f)\n",
    "    review = (open_f.read()).replace(\"<br />\",\"\\n\")\n",
    "    #print review\n",
    "    file_name = f\n",
    "    file_id = int(f.split(\"_\")[0])\n",
    "    rating = int((f.split(\"_\")[1]).split(\".\")[0])\n",
    "    unique_id = dataset + str(file_id) \n",
    "    train_pos_df.loc[len(train_pos_df)] = [unique_id,file_name,file_id,rating,review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_df = pd.DataFrame(columns=[\"Unique ID\",\"File Name\",\"File ID\",\"Rating\",\"Review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.7 s, sys: 212 ms, total: 47 s\n",
      "Wall time: 46.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = \"train_neg_\"\n",
    "for f in train_neg_files:\n",
    "    open_f = open(train_neg_folder+f)\n",
    "    review = (open_f.read()).replace(\"<br />\",\"\\n\")\n",
    "    #print review\n",
    "    file_name = f\n",
    "    file_id = int(f.split(\"_\")[0])\n",
    "    rating = int((f.split(\"_\")[1]).split(\".\")[0])\n",
    "    unique_id = dataset + str(file_id) \n",
    "    train_neg_df.loc[len(train_neg_df)] = [unique_id,file_name,file_id,rating,review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_pos_df, train_neg_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Label\"] = \"neg\"\n",
    "train_df.loc[train_df[\"Rating\"] >= 5, \"Label\"] = \"pos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "neg    12500\n",
       "pos    12500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(\"Label\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import word_tokenize\n",
    "import pdb\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def tokenize_text(txt):\n",
    "    \n",
    "    if len(txt.split()) < 10:\n",
    "            return []\n",
    "    txt = re.sub(r\"[^A-Za-z]\", \" \", txt)\n",
    "    txt = re.sub(r\"\\\"\", \" \\\" \", txt)\n",
    "    txt = re.sub(r\",\", \" , \", txt)\n",
    "    txt = re.sub(r\"\\(\", \" ( \", txt)\n",
    "    txt = re.sub(r\"\\)\", \" ) \", txt)\n",
    "    txt = re.sub(r\"\\s{2,}\", \" \", txt)\n",
    "    \n",
    "    tokens = word_tokenize(txt)\n",
    "    \n",
    "    #tokens.append('length_' + str(len(tokens) / 10))\n",
    "    \n",
    "    tokens = [stemmer.stem(tok) for tok in tokens if (len(tok) > 2) or (tok in string.punctuation)]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"Review\"]\n",
    "y_train = train_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Abhishek/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 40s, sys: 4.16 s, total: 6min 44s\n",
      "Wall time: 6min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, tokenizer=tokenize_text, ngram_range=(1, 3))\n",
    "\n",
    "params_svc = {'C': [0.01, 0.05, 0.1, 0.3, 1, 3, 5, 10]}\n",
    "#params_svc = {'C': [.1, 0.5, 1, 5, 10]}\n",
    "gridsearch = GridSearchCV(LinearSVC(class_weight='balanced'), \n",
    "                   params_svc, cv=5, scoring='recall_micro')\n",
    "\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('clf', gridsearch)])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10}\n"
     ]
    }
   ],
   "source": [
    "print gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = train_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 23s, sys: 624 ms, total: 2min 24s\n",
      "Wall time: 2min 24s\n",
      "CPU times: user 25.5 s, sys: 16 ms, total: 25.5 s\n",
      "Wall time: 25.5 s\n",
      "-------------------------\n",
      "CPU times: user 2min 22s, sys: 536 ms, total: 2min 22s\n",
      "Wall time: 2min 22s\n",
      "CPU times: user 25.5 s, sys: 16 ms, total: 25.5 s\n",
      "Wall time: 25.5 s\n",
      "-------------------------\n",
      "CPU times: user 2min 22s, sys: 748 ms, total: 2min 23s\n",
      "Wall time: 2min 23s\n",
      "CPU times: user 25.4 s, sys: 76 ms, total: 25.5 s\n",
      "Wall time: 25.5 s\n",
      "-------------------------\n",
      "CPU times: user 2min 24s, sys: 552 ms, total: 2min 25s\n",
      "Wall time: 2min 25s\n",
      "CPU times: user 25.1 s, sys: 28 ms, total: 25.1 s\n",
      "Wall time: 25.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Abhishek/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/Abhishek/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "CPU times: user 2min 27s, sys: 456 ms, total: 2min 27s\n",
      "Wall time: 2min 27s\n",
      "CPU times: user 24.5 s, sys: 12 ms, total: 24.5 s\n",
      "Wall time: 24.5 s\n",
      "-------------------------\n",
      "Average precision: 0.5798193953670985\n",
      "Average recall: 0.5342\n",
      "Average f1: 0.5553946660258815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pdb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "df_errors_dfs = []\n",
    "\n",
    "avg_precision = 0\n",
    "avg_recall = 0\n",
    "avg_f1 = 0\n",
    "\n",
    "#vectorizer = TfidfVectorizer(sublinear_tf=True, tokenizer=tokenize_text, ngram_range=(1, 3))\n",
    "kf = KFold(n_splits = 5)\n",
    "for train_inds, test_inds in kf.split(X_train_df):\n",
    "    \n",
    "    cv_train_df = X_train_df.iloc[train_inds, :]\n",
    "    cv_test_df = X_train_df.iloc[test_inds, :]\n",
    "    \n",
    "    train_sents = cv_train_df['Review']\n",
    "    train_labels = cv_train_df['Label']\n",
    "    test_ids = cv_test_df['Unique ID']\n",
    "    test_sents = cv_test_df['Review']\n",
    "    test_labels = cv_test_df['Label']\n",
    "    \n",
    "    # Using best params: re-assemble pipeline (using best classifier) and train model\n",
    "    clf = gridsearch.best_estimator_\n",
    "    #clf = LinearSVC(class_weight='balanced', C=5)\n",
    "    pipe = Pipeline([('vectorizer', vectorizer), ('clf', clf)])\n",
    "    %time pipe.fit(train_sents, train_labels)            \n",
    "    %time test_preds = pipe.predict(test_sents)\n",
    "    \n",
    "    calibrated_model = CalibratedClassifierCV(clf, cv=5)\n",
    "    calibrated_model.fit(vectorizer.transform(train_sents), train_labels)\n",
    "    test_preds_scores = calibrated_model.predict_proba(vectorizer.transform(test_sents))\n",
    "    test_preds_scores = test_preds_scores[:,[0]]\n",
    "        \n",
    "    avg_precision += precision_score(test_labels, test_preds, pos_label = 'pos')\n",
    "    avg_recall += recall_score(test_labels, test_preds, pos_label = 'pos')\n",
    "    avg_f1 += f1_score(test_labels, test_preds, pos_label = 'pos')\n",
    "\n",
    "    df_errors_subset = pd.DataFrame()\n",
    "    df_errors_subset['Unique ID'] = test_ids\n",
    "    df_errors_subset['Review'] = test_sents\n",
    "    df_errors_subset['Label'] = test_labels\n",
    "    df_errors_subset['Model Prediction'] = test_preds\n",
    "    df_errors_subset['Prediction Probability'] = test_preds_scores\n",
    "    \n",
    "    df_errors_subset = df_errors_subset[df_errors_subset['Label'] != df_errors_subset['Model Prediction']]\n",
    "    df_errors_dfs.append(df_errors_subset)\n",
    "    \n",
    "    print 25*'-'\n",
    "    \n",
    "df_errors_train = pd.concat(df_errors_dfs)\n",
    "\n",
    "print \"Average precision: \" + str(avg_precision / 5.0)\n",
    "print \"Average recall: \" + str(avg_recall / 5.0)\n",
    "print \"Average f1: \" + str(avg_f1 / 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "text_clf = Pipeline([('vect', vectorizer), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(2,3),(2,4)],\n",
    "            'tfidf__use_idf': (True, False),\n",
    "            'clf__alpha': ( 1, 1e-1, 1e-2, 1e-3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89812\n",
      "{'vect__ngram_range': (1, 4), 'tfidf__use_idf': True, 'clf__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print gs_clf.best_score_\n",
    "print gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=30):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for i, c in enumerate(clf.coef_):\n",
    "        print \"Most Predictive Features for:\"\n",
    "        coefs_with_fns = sorted(zip(c, feature_names))\n",
    "        top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "        for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "            print \"\\t%.4f\\t%-15s\\t\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_most_informative_features(vectorizer, text_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
